{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from pandas.tseries.offsets import DateOffset \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lineartree import LinearTreeRegressor\n",
    "from joblib import dump, load\n",
    "import requests\n",
    "import xmltodict\n",
    "import joblib\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bdf_request(dataset, id_list):\n",
    "    token = \"8c405577-925f-4f96-9a89-df95aceb3e61\"\n",
    "    url = f\"https://api.webstat.banque-france.fr/webstat-fr/v1/data/{dataset}/\"\n",
    "    \n",
    "    for id in id_list:\n",
    "        url = url + id + \"+\"\n",
    "\n",
    "    headers = {\n",
    "    \"X-IBM-Client-Id\": token,\n",
    "    \"accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "    # \"startPeriod\": \"2020-Q1\",\n",
    "    # \"endPeriod\": \"2020-Q2\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "def parse_bdf_request(data):\n",
    "    df = pd.DataFrame(columns=['Date'])\n",
    "    for serie in data['seriesObs']:\n",
    "        sub_df = pd.DataFrame()\n",
    "        dates = []\n",
    "        values = []\n",
    "        for obs in serie['ObservationsSerie']['observations']:\n",
    "            dates.append(obs['ObservationPeriod']['periodFirstDate'])\n",
    "            values.append(pd.to_numeric(obs['ObservationPeriod']['value']))\n",
    "        sub_df['Date'] = dates\n",
    "        sub_df[serie['ObservationsSerie']['title']] = values\n",
    "        df = df.merge(sub_df, on='Date', how='outer')\n",
    "\n",
    "    if serie['ObservationsSerie']['frequency'] == 'A':\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format=\"%d-%m-%Y %H:%M:%S\") + pd.offsets.MonthEnd(12)\n",
    "    elif serie['ObservationsSerie']['frequency'] == 'Q':\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format=\"%d-%m-%Y %H:%M:%S\") + pd.offsets.MonthEnd(3)  \n",
    "    elif serie['ObservationsSerie']['frequency'] == 'M':\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format=\"%d-%m-%Y %H:%M:%S\") + pd.offsets.MonthEnd(1) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_bdf_ids_1 = [\n",
    "    'CFT.Q.N.FR.W0.S1M.S1.N.A.LE.F62A._Z._Z.XDC._T.S.V.N._T',\n",
    "    'CFT.Q.N.FR.W0.S1M.S1.N.A.LE.F62B._Z._Z.XDC._T.S.V.N._T'\n",
    "]\n",
    "\n",
    "quarterly_bdf_ids_2 = [\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.A.LE.F2.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.L.F.F8.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.A.F.F8.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.L.F.F4.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.A.F.F4.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.A.F.F3.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.A.F.F5._Z._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S1M.S1.N.L.F.F5._Z._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.L.F.F3.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.A.F.F3.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.L.F.F5._Z._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.A.F.F51._Z._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.A.LE.F8.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.L.LE.F8.T._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.A.F.F6._Z._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.L.F.F6._Z._Z.XDC._T.S.V.N._T',\n",
    "    'CNF.Q.N.FR.W0.S11.S1.N.A.LE.F521._Z._Z.XDC._T.S.V.N._T'\n",
    "]\n",
    "\n",
    "monthly_bdf_ids_1 = [\n",
    "    'BSI1.M.FR.N.A.L21.A.1.U6.2250.Z01.E',\n",
    "    'BSI1.M.FR.N.A.L22.A.1.U6.2250.Z01.E',\n",
    "    'BSI1.M.FR.N.A.L22FRPL.A.1.U6.2251.Z01.E',\n",
    "    'BSI1.M.FR.N.A.L23.A.1.U6.2250.Z01.E',\n",
    "    'BSI1.M.FR.N.A.L23FRLA.A.1.U6.2250.Z01.E',\n",
    "    'BSI1.M.FR.N.A.L23FRLD.A.1.U6.2251.Z01.E',\n",
    "    'BSI1.M.FR.N.R.A220Z.A.1.U6.2250.Z01.E',\n",
    "    'BSI1.M.FR.N.R.A210Z.A.1.U6.2250.Z01.E',\n",
    "    'BSI1.M.FR.N.R.A2N1Z.A.1.U6.2240.Z01.E',\n",
    "    'BSI1.M.FR.N.R.A2N2Z.A.1.U6.2240.Z01.E',\n",
    "    'BSI1.M.FR.N.F.L30.A.8.Z5.0000.Z01.T',\n",
    "    'BSI1.M.FR.N.A.L22.A.1.U6.2240.Z01.E',\n",
    "    'BSI1.M.FR.N.A.L21.A.1.U6.2240.Z01.E',\n",
    "    'BSI1.M.FR.Y.R.A220Z.A.4.U6.2254FR.Z01.E',\n",
    "    'BSI1.M.FR.N.R.A220Z.A.4.U6.2254FR.Z01.E'\n",
    "]\n",
    "\n",
    "monthly_bdf_ids_2 = [\n",
    "    'MIR1.M.FR.B.A22.A.5.A.2254U6.EUR.N',\n",
    "    'MIR1.M.FR.B.A2B.A.5.A.2250U6.EUR.N',\n",
    "    'MIR1.M.FR.B.A22HR.A.5.A.2254U6.EUR.N'\n",
    "    \n",
    "]\n",
    "\n",
    "monthly_bdf_ids_3 = [\n",
    "    'MIR.M.FR.B.L22.H.R.A.2240.EUR.N'\n",
    "]\n",
    "\n",
    "data_bdf_quarterly_1 = bdf_request('CFT', quarterly_bdf_ids_1)\n",
    "df_bdf_quarterly_1 = parse_bdf_request(data_bdf_quarterly_1)\n",
    "\n",
    "data_bdf_quarterly_2 = bdf_request('CNF', quarterly_bdf_ids_2)\n",
    "df_bdf_quarterly_2 = parse_bdf_request(data_bdf_quarterly_2)\n",
    "\n",
    "df_bdf_quarterly = df_bdf_quarterly_1.merge(df_bdf_quarterly_2, on='Date', how='outer')\n",
    "df_bdf_quarterly = df_bdf_quarterly.sort_values('Date', ascending=False)\n",
    "for col in df_bdf_quarterly.columns:\n",
    "    if col != 'Date':\n",
    "        df_bdf_quarterly[col] = df_bdf_quarterly[col] * 1e3\n",
    "display(df_bdf_quarterly.head())\n",
    "\n",
    "data_bdf_monthly_1 = bdf_request('BSI1', monthly_bdf_ids_1)\n",
    "df_bdf_monthly_1 = parse_bdf_request(data_bdf_monthly_1)\n",
    "\n",
    "data_bdf_monthly_2 = bdf_request('MIR1', monthly_bdf_ids_2)\n",
    "df_bdf_monthly_2 = parse_bdf_request(data_bdf_monthly_2)\n",
    "for col in df_bdf_monthly_2.columns:\n",
    "    if col != 'Date':\n",
    "        df_bdf_monthly_2[col] = df_bdf_monthly_2[col] * 1e3\n",
    "\n",
    "data_bdf_monthly_3 = bdf_request('MIR', monthly_bdf_ids_3)\n",
    "df_bdf_monthly_3 = parse_bdf_request(data_bdf_monthly_3)\n",
    "\n",
    "df_bdf_monthly = df_bdf_monthly_1.merge(df_bdf_monthly_2, on='Date', how='outer').merge(df_bdf_monthly_3, on='Date', how='outer')\n",
    "df_bdf_monthly = df_bdf_monthly.sort_values('Date', ascending=False)\n",
    "df_bdf_monthly[[\"Titres d'OPC monétaires, taux de valorisation de l'encours\", \"Taux d'intérêt sur contrats nouveaux, DAT, SNF, durée supérieure à 2 ans\"]] = df_bdf_monthly[[\"Titres d'OPC monétaires, taux de valorisation de l'encours\", \"Taux d'intérêt sur contrats nouveaux, DAT, SNF, durée supérieure à 2 ans\"]] / 100\n",
    "display(df_bdf_monthly.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insee_request(id_list):\n",
    "    token = \"fd13b343-b9d7-385d-9ae3-a3e53b5a0440\"\n",
    "    url = \"https://bdm.insee.fr/series/sdmx/data/SERIES_BDM/\"\n",
    "    \n",
    "    for id in id_list:\n",
    "        url = url + id + \"+\"\n",
    "\n",
    "    headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "    # \"startPeriod\": \"2020-Q1\",\n",
    "    # \"endPeriod\": \"2020-Q2\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    data = xmltodict.parse(response.content)\n",
    "    return data\n",
    "\n",
    "    \n",
    "\n",
    "def parse_insee_request(data):\n",
    "    df = pd.DataFrame(columns=['Date'])\n",
    "\n",
    "    if type(data['message:StructureSpecificData']['message:DataSet']['Series']) == list:\n",
    "        series = data['message:StructureSpecificData']['message:DataSet']['Series']\n",
    "    else:\n",
    "        series = [data['message:StructureSpecificData']['message:DataSet']['Series']]\n",
    "\n",
    "    for serie in series:\n",
    "        sub_df = pd.DataFrame()\n",
    "        unit_mult = 10**float(serie['@UNIT_MULT'])\n",
    "        dates = []\n",
    "        values = []\n",
    "        for obs in serie['Obs']:\n",
    "            dates.append(obs['@TIME_PERIOD'])\n",
    "            values.append(float(obs['@OBS_VALUE']) * unit_mult)\n",
    "        sub_df['Date'] = dates\n",
    "        \n",
    "        sub_df[serie['@TITLE_FR']] = values\n",
    "        df = df.merge(sub_df, on='Date', how='outer')\n",
    "\n",
    "    if serie['@FREQ'] == 'A':\n",
    "        df['Date'] = pd.to_datetime(df['Date']) + pd.offsets.MonthEnd(12)\n",
    "    elif serie['@FREQ'] == 'T':\n",
    "        df['Date'] = pd.to_datetime(df['Date']) + pd.offsets.MonthEnd(3)  \n",
    "    elif serie['@FREQ'] == 'M':\n",
    "        df['Date'] = pd.to_datetime(df['Date']) + pd.offsets.MonthEnd(1)  \n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_insee_ids = [\n",
    "    '010564058',\n",
    "    '010563884'\n",
    "    # '010563893',\n",
    "]\n",
    "\n",
    "quarterly_insee_ids = [\n",
    "    '010564925', #RDB courant\n",
    "    '010565711', #Conso ménages courant\n",
    "    '010565712', #Conso ménages constant\n",
    "    '010564934', #Epargne ménages courant,\n",
    "    '010565738', #FBCF courant ménages\n",
    "    '010565734', #FBCF constant ménages\n",
    "    '010565724', #Exportation courant\n",
    "    '010565725', #Exportation constant\n",
    "    '010565726', #Import courant\n",
    "    '010565727', #Import constant\n",
    "    '010565717', #Conso totale courant\n",
    "    '010565718', #Conso totale constant\n",
    "    '010564879', #Menages aide à l'investissement,\n",
    "    '010564890',\n",
    "    '010564889',\n",
    "    '010564874',\n",
    "    '010564983',\n",
    "    '010564909',\n",
    "    '010564694',\n",
    "    '010564707',\n",
    "    '010564734',\n",
    "    '010564744',\n",
    "    '010564755',\n",
    "    '010564767',\n",
    "    '010564766',\n",
    "    '010564789',\n",
    "    '010564848',\n",
    "    '010564866',\n",
    "    '010564865',\n",
    "    '010564833',\n",
    "    '010564840',\n",
    "    '010564880',\n",
    "    '010564892',\n",
    "    '010564891',\n",
    "    '010564975',\n",
    "    '010564898',\n",
    "    '010565707',\n",
    "    '010565708',\n",
    "    '010565730',\n",
    "    '010565731',\n",
    "    '010564901',\n",
    "    '010564931',\n",
    "    '010564875',\n",
    "    '010564883',\n",
    "    '010564884',\n",
    "    '010564871',\n",
    "    '010565536',\n",
    "    '010565746',\n",
    "    '010565745'\n",
    "]\n",
    "\n",
    "monthly_insee_ids = [\n",
    "   '001769682' #CPI\n",
    "]\n",
    "\n",
    "data_insee_annual = insee_request(annual_insee_ids)\n",
    "df_insee_annual = parse_insee_request(data_insee_annual)\n",
    "display(df_insee_annual.head())\n",
    "\n",
    "data_insee_quarterly = insee_request(quarterly_insee_ids)\n",
    "df_insee_quarterly = parse_insee_request(data_insee_quarterly)\n",
    "display(df_insee_quarterly.head())\n",
    "\n",
    "data_insee_monthly = insee_request(monthly_insee_ids)\n",
    "df_insee_monthly = parse_insee_request(data_insee_monthly)\n",
    "display(df_insee_monthly.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. SNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = ('2003-03-01', '2022-08-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Arbitrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario = pd.read_excel('20230915 - RUN/Envoi_Data_Scenario_France_Central_APR_20230918.xlsx')\n",
    "df_scenario['Date'] = pd.to_datetime(df_scenario['Date'])\n",
    "df_scenario.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Unique processing \"\"\"\n",
    "df_scenario['RDB_constant'] = df_scenario['RDB_constant (monthly transformed)']\n",
    "df_scenario['RDB_courant'] = df_scenario['RDB_courant (monthly transformed)']\n",
    "df_scenario[\"GDP / current prices, % ch yoy / quarterly\"] = df_scenario[\"GDP / current prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"GDP / constant prices, % ch yoy / quarterly\"] = df_scenario[\"GDP / constant prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Households disposable income / constant prices (deflated by household consumption deflator), % ch yoy / quarterly\"] = df_scenario[\"Households disposable income / constant prices (deflated by household consumption deflator), % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Household consumption / constant prices, % ch yoy / quarterly\"] = df_scenario[\"Household consumption / constant prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Public consumption / constant prices, % ch yoy / quarterly\"] = df_scenario[\"Public consumption / constant prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Investment, private, households / constant prices, % ch yoy / quarterly\"] = df_scenario[\"Investment, private, households / constant prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Imports of goods and services / constant prices, % ch yoy / quarterly\"] = df_scenario[\"Imports of goods and services / constant prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Exports of goods and services / constant prices, % ch yoy / quarterly\"] = df_scenario[\"Exports of goods and services / constant prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"CPI index / % ch yoy / quarterly\"] = df_scenario[\"CPI index / % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Investment, private, NFC / constant prices, % ch yoy / quarterly\"] = df_scenario[\"Investment, private, NFC / constant prices, % ch yoy / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Non financial companies' saving ratio / constant prices, % of value added / quarterly\"] = df_scenario[\"Non financial companies' saving ratio / constant prices, % of value added / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "df_scenario[\"Non financial companies' profit ratio / constant prices, % of value added / quarterly\"] = df_scenario[\"Non financial companies' profit ratio / constant prices, % of value added / quarterly\"].replace(0, np.nan).bfill() / 100\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "df_scenario.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_bdf_monthly[['Date', 'Dépôts à vue des SNF résidentes, encours', 'Dépôts à terme des SNF résidentes, encours']]\n",
    "df_target = df_target.merge(df_bdf_quarterly[[\"Date\", \"Actif Toutes dénominations monétaires des SNF vis-à-vis de toutes contreparties - encours d'OPC monétaires\"]], on='Date', how='left')\n",
    "df_target[\"Actif Toutes dénominations monétaires des SNF vis-à-vis de toutes contreparties - encours d'OPC monétaires\"] = df_target[\"Actif Toutes dénominations monétaires des SNF vis-à-vis de toutes contreparties - encours d'OPC monétaires\"].bfill() / 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNF\n",
    "model_dav_part_stable_SNF = load(f'models/dav_part_stable_SNF.joblib')\n",
    "drivers = ['OAT_10Y_diff', 'EUSW10V3_diff', 'Inflation_diff', 'SNF_flux_credit'] + [f\"month_{i}\" for i in range(3, 13)]\n",
    "\n",
    "df_dav_SNF_histo = df_bdf_monthly[['Date', \"Crédits à l'investissement accordés aux sociétés non financières résidentes, encours\", \"Crédits de trésorerie accordés aux sociétés non financières résidentes, encours\", \"Dépôts à vue des SNF résidentes, encours\"]]\n",
    "df_dav_SNF_histo = df_dav_SNF_histo.merge(df_scenario, on='Date', how='left')\n",
    "df_dav_SNF_histo['SNF_flux_credit'] = df_dav_SNF_histo[[\"Crédits à l'investissement accordés aux sociétés non financières résidentes, encours\", \"Crédits de trésorerie accordés aux sociétés non financières résidentes, encours\"]].sum(axis=1).diff()\n",
    "df_dav_SNF_histo['OAT_10Y_diff'] = df_dav_SNF_histo['OAT_10Y'].diff()\n",
    "df_dav_SNF_histo['EUSW10V3_diff'] = df_dav_SNF_histo['EUSW10V3'].diff()\n",
    "df_dav_SNF_histo['Inflation_diff'] = df_dav_SNF_histo['Inflation'].diff()\n",
    "for i in range(1,13):\n",
    "    df_dav_SNF_histo[f\"month_{i}\"] = (df_dav_SNF_histo['Date'].dt.month == i).astype(int)\n",
    "df_dav_SNF_histo = df_dav_SNF_histo[df_dav_SNF_histo['Date'] >= \"2013-12\"]\n",
    "df_dav_SNF_histo = df_dav_SNF_histo.sort_values('Date', ascending=True)\n",
    "\n",
    "df_dav_SNF_histo['dav_part_stable_SNF_diff'] = model_dav_part_stable_SNF.predict(df_dav_SNF_histo[drivers].fillna(0))\n",
    "dav_part_stable_init =  df_dav_SNF_histo[(df_dav_SNF_histo['Date'].dt.year==2013) & (df_dav_SNF_histo['Date'].dt.month==12)]['Dépôts à vue des SNF résidentes, encours'].values[0] \n",
    "df_dav_SNF_histo['dav_part_stable_SNF_histo'] = dav_part_stable_init + (df_dav_SNF_histo['dav_part_stable_SNF_diff'] * (df_dav_SNF_histo['Date'].dt.year > 2013)).cumsum()\n",
    "\n",
    "df_target = df_target.merge(df_dav_SNF_histo[['Date', 'dav_part_stable_SNF_histo']], on='Date', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target['SNF_DAV_Vol'] = (df_target['Dépôts à vue des SNF résidentes, encours'] - df_target['dav_part_stable_SNF_histo']).fillna(0.)\n",
    "df_target['SNF_DAV_Vol'] = df_target['SNF_DAV_Vol'].apply(lambda x: max(x, 0))\n",
    "df_target['SNF_DAT'] = df_target['Dépôts à terme des SNF résidentes, encours']\n",
    "df_target['SNF_OPC'] = df_target[\"Actif Toutes dénominations monétaires des SNF vis-à-vis de toutes contreparties - encours d'OPC monétaires\"]\n",
    "\n",
    "df_drivers = df_scenario.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Arbitration model fit \"\"\"\n",
    "\n",
    "'''LOADING DATA SOURCES'''\n",
    "\n",
    "\n",
    "# Loading file containing historical drivers used to fit models as well as the drivers used for projection \n",
    "df_drivers['Date'] = pd.to_datetime(df_drivers['Date'], format='%YM%m')\n",
    "\n",
    "# Loading file containing historical targets (here. France deposits) used to fit models\n",
    "\n",
    "# Building a common dataframe containing drivers and targets\n",
    "df = df_drivers.merge(df_target, on='Date', how='left').replace('n.a.', np.nan)\n",
    "\n",
    "\n",
    "'''Feature engineering'''\n",
    "\n",
    "df['LA_minus_OAT'] = df['LA_rate'] - df['OAT_10Y'].rolling(window=5, min_periods=1).mean()\n",
    "df['OAT_10Y_3YROLLING'] = df['OAT_10Y'].rolling(window=12*3, min_periods=1).mean()\n",
    "df['OAT_10Y_7YROLLING'] = df['OAT_10Y'].rolling(window=12*7, min_periods=1).mean()\n",
    "# df['Menages_DAV_Stable'] = df['Menages_DAV'] - df['Menages_DAV_Vol']\n",
    "# df['Epargne_menages_ratio'] = df['Epargne_menages_courant'] / df['RDB_courant']\n",
    "\n",
    "\n",
    "'''Selecting training range and prediction range'''\n",
    "\n",
    "# Picking historical training range in years/date (bounds included)\n",
    "# train_range = ('2003-03-01', '2022-09-01')\n",
    "# backtest_range = ('2022-04-01', '2022-09-01')\n",
    "# prediction_range = ('2022-06-01', '2027-12-01')\n",
    "\n",
    "\n",
    "'''Selecting drivers used to make predictions as well as model types'''\n",
    "\n",
    "target_to_drivers = {\n",
    "    \"SNF_DAV_Vol\": [\"Euribor_3M\"],\n",
    "    \"SNF_DAT\": [\"OAT_10Y_3YROLLING\", \"Euribor_3M_6MROLLING\"],\n",
    "    \"SNF_OPC\": [\"OAT_10Y_7YROLLING\", \"CAC40\"]\n",
    "}\n",
    "reference = 'Euribor_3M'\n",
    "\n",
    "models = {\n",
    "    \"SNF_DAV_Vol\": DecisionTreeRegressor(max_depth=3, min_samples_leaf=5),\n",
    "    \"SNF_DAT\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"SNF_OPC\": DecisionTreeRegressor(max_depth=3)\n",
    "}\n",
    "\n",
    "\n",
    "'''CALIBRAGE ET PREDICTION'''\n",
    "\n",
    "df_train = df[(df['Date']<=train_range[1]) & (df['Date']>=train_range[0])]\n",
    "\n",
    "global_shift = 0\n",
    "df_train['total'] = df_train[target_to_drivers.keys()].sum(axis=1)\n",
    "for (k,v) in target_to_drivers.items():\n",
    "    df_train[k+'_ratio'] = df_train[k]/df_train['total']\n",
    "    max_shift = 0\n",
    "    for driver in v:\n",
    "        if '_shifted_' in driver:\n",
    "            shift_val = int(driver.split('_')[-1])\n",
    "            df_train[driver] = df_train['_'.join(driver.split('_')[:-2])].shift(shift_val).fillna(0)\n",
    "            max_shift = max(max_shift, shift_val)\n",
    "            global_shift = max(global_shift, shift_val)\n",
    "        elif '_variation' in driver:\n",
    "            df_train[driver] = ((df_train['_'.join(driver.split('_')[:-1])] - df_train['_'.join(driver.split('_')[:-1])].shift(1)) / df_train['_'.join(driver.split('_')[:-1])].shift(1)).fillna(0.)\n",
    "        elif '_referenced' in driver:\n",
    "            df_train[driver] = (df_train['_'.join(driver.split('_')[:-1])] / df_train[reference]).fillna(0.)\n",
    "        elif \"_6MROLLING\" in driver:\n",
    "            df_train[driver] = df_train['_'.join(driver.split('_')[:-1])].rolling(6, min_periods=1).mean()\n",
    "    df_train_shift = df_train[df_train['Date']>=df_train['Date'].min()+ DateOffset(months=max_shift)]\n",
    "    # if k==\"SNF_DAV_Vol\":\n",
    "    #     df_train_shift = df_train_shift[df_train_shift['Date']>=\"2013-04-01\"]\n",
    "    models[k] = models[k].fit(df_train_shift[v], df_train_shift[k+'_ratio'])\n",
    "    model = models[k]\n",
    "    df_train[k+'_ratio_predicted'] = model.predict(df_train[v])\n",
    "    df_train[k+'_ratio_predicted_adjusted'] = df_train[k+'_ratio_predicted'].apply(lambda x: max(x,0))\n",
    "\n",
    "standardization_factor = df_train[[x+'_ratio_predicted_adjusted' for x in target_to_drivers.keys()]].sum(axis=1)\n",
    "for (k,v) in target_to_drivers.items():\n",
    "    df_train[k+'_ratio_predicted_adjusted'] = df_train[k+'_ratio_predicted_adjusted'] / standardization_factor\n",
    "    df_train[k+'_predicted'] = df_train[k+'_ratio_predicted_adjusted']*df_train['total']\n",
    "\n",
    "df_plot = df_train.copy()\n",
    "df_plot = df_plot[df_plot['Date']>=df_plot['Date'].min()+ DateOffset(months=global_shift)].set_index('Date')\n",
    "for k in target_to_drivers.keys():\n",
    "    fig, ax =plt.subplots(1,1)\n",
    "    fig.set_figheight(4.5)\n",
    "    fig.set_figwidth(15.2)\n",
    "    \n",
    "    if k==\"Menages_DAV_Vol\":\n",
    "        figure = sns.lineplot(data=df_plot[df_plot.index>=\"2015-04-01\"][[k+'_ratio', k+'_ratio_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} ratio fit : train on [2015-04-01, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot[df_plot.index>=\"2015-04-01\"].index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[df_plot.index>=\"2015-04-01\"][[k, k+'_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} : train on [2015-04-01, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot[df_plot.index>=\"2015-04-01\"].index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        for driver in target_to_drivers[k]:\n",
    "            df_plot[driver+'_normalized'] = (df_plot[driver] - df_plot[driver].min()) / (df_plot[driver].max() - df_plot[driver].min())\n",
    "\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[df_plot.index>=\"2015-04-01\"][[d+'_normalized' for d in target_to_drivers[k]]], ax=ax)\n",
    "        figure.set_title(f\"{k} : Drivers in [2015-04-01, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot[df_plot.index>=\"2015-04-01\"].index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        figure = sns.lineplot(data=df_plot[[k+'_ratio', k+'_ratio_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} ratio fit : train on [{train_range[0]}, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot.index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[[k, k+'_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} : train on [{train_range[0]}, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot.index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        for driver in target_to_drivers[k]:\n",
    "            df_plot[driver+'_normalized'] = (df_plot[driver] - df_plot[driver].min()) / (df_plot[driver].max() - df_plot[driver].min())\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[[d+'_normalized' for d in target_to_drivers[k]]], ax=ax)\n",
    "        figure.set_title(f\"{k} : Drivers in [{train_range[0]}, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot.index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "    fig, ax =plt.subplots(1,1)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(16)\n",
    "\n",
    "    if k==\"Menages_DAV_Vol\":\n",
    "        tree.plot_tree(models[k], feature_names=[d[:12] for d in target_to_drivers[k]], ax=ax)\n",
    "        fig.suptitle(f\"{k} : tree representation, train on [2015-04-01, {train_range[1]}]\", fontsize=20)\n",
    "    else:  \n",
    "        tree.plot_tree(models[k], feature_names=[d[:15] for d in target_to_drivers[k]], ax=ax)\n",
    "        fig.suptitle(f\"{k} : tree representation, train on [{train_range[0]}, {train_range[1]}]\", fontsize=20)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "for k, v in models.items():\n",
    "    joblib.dump(v, f\"models/arbitrage_SNF/{k}.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crédit investissement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "df_y = df_bdf_monthly[[\"Date\", \"Crédits à l'investissement accordés aux sociétés non financières résidentes, encours\"]]\n",
    "df_x = pd.read_excel(\"Data_Scenario.xlsx\")\n",
    "df_x = df_x.merge(df_insee_quarterly, on='Date', how='left')\n",
    "for col in df_insee_quarterly.columns:\n",
    "    if col != 'Date':\n",
    "        df_x[col] = df_x[col].bfill() / (1e6 * 3)\n",
    "\n",
    "df = df_y.merge(df_x, on=\"Date\", how=\"left\")\n",
    "df = df.sort_values('Date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "df.rename(columns={\"Crédits à l'investissement accordés aux sociétés non financières résidentes, encours\": \"Crédit_invest\"}, inplace=True)\n",
    "\n",
    "df['OAT_10Y_minus_inflation'] = df['OAT_10Y'] - df['Inflation']\n",
    "df['Crédit_invest_diff'] = df['Crédit_invest'].diff()\n",
    "\n",
    "for i in range(1, 7):\n",
    "    df[f'Crédit_invest_shift_{i}'] = df['Crédit_invest'].shift(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = (\"2001-01-01\", \"2018-06-01\")\n",
    "backtest_range = (\"2018-07-01\", \"2019-12-01\")\n",
    "\n",
    "df_train = df[(df['Date']>=train_range[0]) & (df['Date']<=train_range[1])]\n",
    "display(df_train.head())\n",
    "\n",
    "df_backtest = df[(df['Date']>=backtest_range[0]) & (df['Date']<=backtest_range[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amort_stock = 12 * 4\n",
    "amort = 12 * 7\n",
    "\n",
    "drivers = [\"Investissement des entreprises non financières - Total - Volume aux prix de l'année précédente chaînés - Série CVS-CJO\", 'OAT_10Y_minus_inflation']\n",
    "\n",
    "timesteps = df_train.shape[0]\n",
    "encours_init = df[df[\"Date\"]<train_range[0]]['Crédit_invest'].values[-1]\n",
    "\n",
    "stock_outstanding = [max(encours_init * (1 - i / amort_stock), 0) for i in range(1, timesteps+1)]\n",
    "target_outstanding = df_train['Crédit_invest'].values\n",
    "\n",
    "target_np = target_outstanding - stock_outstanding\n",
    "\n",
    "np_amort_matrix_init = np.array([max(1 - i / amort, 0) for i in range(timesteps)])\n",
    "np_amort_matrix = np.array([np_amort_matrix_init])\n",
    "for i in range(1, timesteps):\n",
    "    np_amort_matrix = np.concatenate([np_amort_matrix, np.roll(np_amort_matrix_init, i)[None, :]])\n",
    "np_amort_matrix = np.triu(np_amort_matrix)\n",
    "\n",
    "new_prod = np.linalg.solve(np_amort_matrix.T, target_np)\n",
    "\n",
    "lr = LinearRegression().fit(df_train[drivers], new_prod)\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(lr, 'models/_new/credit_investissement.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_new_prods = lr.predict(df_train[drivers])\n",
    "predict_new_prods = np.triu(np.ones((timesteps, timesteps))) * predict_new_prods[:, None]\n",
    "predict_new_prods = predict_new_prods * np_amort_matrix\n",
    "\n",
    "predict_outstanding = np.sum(predict_new_prods, axis=0) + stock_outstanding\n",
    "\n",
    "df_train['Crédit_invest_predict'] = predict_outstanding\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_figheight(4.5)\n",
    "fig.set_figwidth(15.2)\n",
    "figure = sns.lineplot(data=df_train.set_index(\"Date\")[[\"Crédit_invest\", \"Crédit_invest_predict\"]], ax=ax)\n",
    "figure.set_title(f\"fit : train on [{train_range[0]}, {train_range[1]}]\")\n",
    "mape = sk.metrics.mean_absolute_percentage_error(df_train['Crédit_invest'], df_train['Crédit_invest_predict'])\n",
    "print(f\"fit : MAPE of {round(100*mape, 2)}%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps_total = timesteps + df_backtest.shape[0]\n",
    "\n",
    "past_new_prods = new_prod\n",
    "predict_new_prods = lr.predict(df_backtest[drivers])\n",
    "total_new_prods = np.concatenate([past_new_prods, predict_new_prods])\n",
    "total_new_prods = np.triu(np.ones((timesteps_total, timesteps_total))) * total_new_prods[:, None]\n",
    "\n",
    "np_amort_matrix_init = np.array([max(1 - i / amort, 0) for i in range(timesteps_total)])\n",
    "np_amort_matrix = np.array([np_amort_matrix_init])\n",
    "for i in range(1, timesteps_total):\n",
    "    np_amort_matrix = np.concatenate([np_amort_matrix, np.roll(np_amort_matrix_init, i)[None, :]])\n",
    "np_amort_matrix = np.triu(np_amort_matrix)\n",
    "\n",
    "total_new_prods = total_new_prods * np_amort_matrix\n",
    "stock_outstanding = [max(encours_init * (1 - i / amort_stock), 0) for i in range(1, timesteps_total+1)]\n",
    "\n",
    "total_outstanding = np.sum(total_new_prods, axis=0) + stock_outstanding\n",
    "\n",
    "df_backtest['Crédit_invest_predict'] = total_outstanding[timesteps:]\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_figheight(4.5)\n",
    "fig.set_figwidth(15.2)\n",
    "figure = sns.lineplot(data=df_backtest.set_index(\"Date\")[[\"Crédit_invest\", \"Crédit_invest_predict\"]], ax=ax)\n",
    "figure.set_title(f\"validation : backtest on [{backtest_range[0]}, {backtest_range[1]}]\")\n",
    "mape = sk.metrics.mean_absolute_percentage_error(df_backtest['Crédit_invest'], df_backtest['Crédit_invest_predict'])\n",
    "print(f\"fit : MAPE of {round(100*mape, 2)}%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crédit trésorerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "df_y = df_bdf_monthly[[\"Date\", \"Crédits de trésorerie accordés aux sociétés non financières résidentes, encours\"]]\n",
    "df_x = pd.read_excel(\"Data_Scenario.xlsx\")\n",
    "df_x = df_x.merge(df_insee_quarterly, on='Date', how='left')\n",
    "for col in df_insee_quarterly.columns:\n",
    "    if col != 'Date':\n",
    "        df_x[col] = df_x[col].bfill() / (1e6 * 3)\n",
    "\n",
    "df = df_y.merge(df_x, on=\"Date\", how=\"left\")\n",
    "df = df.sort_values('Date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "df.rename(columns={\"Crédits de trésorerie accordés aux sociétés non financières résidentes, encours\": \"Crédit_treso\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = (\"2001-01-01\", \"2018-06-01\")\n",
    "backtest_range = (\"2018-07-01\", \"2019-12-01\")\n",
    "\n",
    "df_train = df[(df['Date']>=train_range[0]) & (df['Date']<=train_range[1])]\n",
    "display(df_train.head())\n",
    "\n",
    "df_backtest = df[(df['Date']>=backtest_range[0]) & (df['Date']<=backtest_range[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amort_stock = 12 * 4\n",
    "amort = 12 * 7\n",
    "\n",
    "drivers = [\"Investissement des entreprises non financières - Total - Valeur aux prix courants - Série CVS-CJO\", 'OAT_10Y']\n",
    "\n",
    "lr = LinearRegression().fit(df_train[drivers], df_train[\"Crédit_treso\"])\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(lr, 'models/_new/credit_tresorerie.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Crédit_treso_predict'] = lr.predict(df_train[drivers])\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_figheight(4.5)\n",
    "fig.set_figwidth(15.2)\n",
    "figure = sns.lineplot(data=df_train.set_index(\"Date\")[[\"Crédit_treso\", \"Crédit_treso_predict\"]], ax=ax)\n",
    "figure.set_title(f\"fit : train on [{train_range[0]}, {train_range[1]}]\")\n",
    "mape = sk.metrics.mean_absolute_percentage_error(df_train['Crédit_treso'], df_train['Crédit_treso_predict'])\n",
    "print(f\"fit : MAPE of {round(100*mape, 2)}%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backtest['Crédit_treso_predict'] = lr.predict(df_backtest[drivers])\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_figheight(4.5)\n",
    "fig.set_figwidth(15.2)\n",
    "figure = sns.lineplot(data=df_backtest.set_index(\"Date\")[[\"Crédit_treso\", \"Crédit_treso_predict\"]], ax=ax)\n",
    "figure.set_title(f\"validation : backtest on [{backtest_range[0]}, {backtest_range[1]}]\")\n",
    "mape = sk.metrics.mean_absolute_percentage_error(df_backtest['Crédit_treso'], df_backtest['Crédit_treso_predict'])\n",
    "print(f\"fit : MAPE of {round(100*mape, 2)}%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Menages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Arbitrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_bdf_monthly.copy()\n",
    "df_target = df_target.merge(df_bdf_quarterly, on='Date', how='left')\n",
    "df_target = df_target.sort_values('Date', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Fitting DAV PART STABLE model \"\"\"\n",
    "\n",
    "df_scenario['RDB_courant_1Yrolling'] = df_scenario['RDB_courant'].rolling(12).mean().bfill()\n",
    "\n",
    "start = pd.to_datetime('2003-12-01')\n",
    "end = pd.to_datetime('2015-05-01')\n",
    "x_train = df_scenario[(df_scenario['Date'] >= start) & (df_scenario['Date'] <= end)].sort_values('Date', ascending=True)['RDB_courant_1Yrolling'].values\n",
    "y_train = df_bdf_monthly[(df_bdf_monthly['Date'] >= start) & (df_bdf_monthly['Date'] <= end)].sort_values('Date', ascending=True)['Dépôts à vue des ménages et ISBLSM résidents, encours'].values\n",
    "\n",
    "model_dav_part_stable = LinearRegression()\n",
    "model_dav_part_stable.fit(x_train.reshape(-1, 1), y_train)\n",
    "\n",
    "print(model_dav_part_stable.intercept_, model_dav_part_stable.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ménages\n",
    "model_dav_part_stable = load(f'models/dav_part_stable.joblib')\n",
    "\n",
    "print(model_dav_part_stable.intercept_, model_dav_part_stable.coef_) #Please note coefficient might slightly change due to BdF data inconsistency over time\n",
    "\n",
    "df_scenario['RDB_courant_1Yrolling'] = df_scenario['RDB_courant'].rolling(12).mean().bfill()\n",
    "df_scenario['dav_part_stable'] = model_dav_part_stable.predict(df_scenario[['RDB_courant_1Yrolling']])\n",
    "\n",
    "df_target = df_target.merge(df_scenario[['Date', 'dav_part_stable']], on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target[\"__Livrets A des ménages et ISBLSM résidents, encours\"] = df_target[\"Livrets A des ménages et ISBLSM résidents, encours\"].bfill()\n",
    "df_target[\"__Livrets A des ménages et ISBLSM résidents, encours\"] = df_target[\"__Livrets A des ménages et ISBLSM résidents, encours\"]\n",
    "df_target[\"__coeff\"] = df_target[\"Livrets de développement durable et solidaire des ménages résidents, encours\"].shift(1) / df_target[\"Livrets de développement durable et solidaire des ménages résidents, encours\"]\n",
    "df_target[\"__coeff\"] = ~df_target[\"Livrets A des ménages et ISBLSM résidents, encours\"].isnull() + df_target[\"Livrets A des ménages et ISBLSM résidents, encours\"].isnull() * df_target[\"__coeff\"]\n",
    "df_target[\"__coeff\"] = df_target['__coeff'][::-1].cumprod()[::-1]\n",
    "df_target['Livrets A des ménages et ISBLSM résidents, encours'] = df_target['__Livrets A des ménages et ISBLSM résidents, encours'] * df_target['__coeff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_target['Menages_DAV'] = df_target[\"Dépôts à vue des ménages et ISBLSM résidents, encours\"]\n",
    "df_target['DAV_STABLE'] = df_target['dav_part_stable']\n",
    "df_target['Menages_DAV_Vol'] = df_target[\"Dépôts à vue des ménages et ISBLSM résidents, encours\"] - df_target['DAV_STABLE']\n",
    "df_target['Menages_DAT'] = df_target['Dépôts à terme des ménages et ISBLSM résidents, encours'] - df_target['PEL des ménages résidents, encours']\n",
    "df_target['Menages_PEL'] = df_target['PEL des ménages résidents, encours']\n",
    "df_target['Menages_Livrets'] = df_target[\"Livrets d'épargne des ménages et ISBLSM résidents, encours\"] - (df_target[\"Livrets A des ménages et ISBLSM résidents, encours\"] + df_target[\"Livrets de développement durable et solidaire des ménages résidents, encours\"])\n",
    "df_target['Menages_LA_LDD'] = df_target[\"Livrets A des ménages et ISBLSM résidents, encours\"] + df_target[\"Livrets de développement durable et solidaire des ménages résidents, encours\"]\n",
    "df_target['Autres'] = (df_target['Actif Toutes dénominations monétaires des ménages vis-à-vis de toutes contreparties - encours de monnaie et dépôts']) / (3 * 1e3) - (df_target['Dépôts à vue des ménages et ISBLSM résidents, encours']+ df_target['Dépôts à terme des ménages et ISBLSM résidents, encours'] + df_target[\"Livrets d'épargne des ménages et ISBLSM résidents, encours\"])\n",
    "df_target['Menages_AV_Euro_Corrige'] = df_target['Assurance-vie support euro, actif des ménages, encours trimestriel'].bfill()\n",
    "df_target['Menages_AV_UC'] = df_target['Assurance-vie en unités de compte, actif des ménages, encours trimestriel'].bfill()\n",
    "\n",
    "df_drivers = df_scenario.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Date', \"Livrets de développement durable et solidaire des ménages résidents, encours\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target['Assurance-vie en unités de compte, actif des ménages, encours trimestriel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Date', 'Menages_AV_Euro_Corrige_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Arbitration model fit \"\"\"\n",
    "\n",
    "'''LOADING DATA SOURCES'''\n",
    "\n",
    "scenario = 'Central' # Stagflation # Adverse\n",
    "\n",
    "# Building a common dataframe containing drivers and targets\n",
    "df = df_drivers.merge(df_target, on='Date', how='left').replace('n.a.', np.nan)\n",
    "\n",
    "\n",
    "'''Feature engineering'''\n",
    "\n",
    "df['LA_minus_OAT'] = df['LA_rate'] - df['OAT_10Y'].rolling(window=5, min_periods=1).mean()\n",
    "df['OAT_10Y_3YROLLING'] = df['OAT_10Y'].rolling(window=12*3, min_periods=1).mean()\n",
    "df['Menages_DAV_Stable'] = df['Menages_DAV'] - df['Menages_DAV_Vol']\n",
    "df = df.merge(df_insee_quarterly[['Date', 'Dépenses de consommation des ménages - Total - Valeur aux prix courants - Série CVS-CJO']], on='Date', how='left')\n",
    "df['Consommation_menages_courant'] = df['Dépenses de consommation des ménages - Total - Valeur aux prix courants - Série CVS-CJO'].bfill().ffill() / (1e6 * 3)\n",
    "df['Epargne_menages_courant'] = df['RDB_courant'] - df['Consommation_menages_courant']\n",
    "df['Epargne_menages_ratio'] = df['Epargne_menages_courant'] / df['RDB_courant']\n",
    "\n",
    "\n",
    "'''Selecting training range and prediction range'''\n",
    "\n",
    "# Picking historical training range in years/date (bounds included)\n",
    "train_range = ('2003-03-01', '2022-09-01')\n",
    "backtest_range = ('2022-04-01', '2022-09-01')\n",
    "prediction_range = ('2022-06-01', '2027-12-01')\n",
    "\n",
    "\n",
    "'''Selecting drivers used to make predictions as well as model types'''\n",
    "\n",
    "target_to_drivers = {\n",
    "    \"Menages_AV_Euro_Corrige\": [\"Euribor_3M_6MROLLING\", \"OAT_10Y_3YROLLING\"],\n",
    "    \"Menages_AV_UC\": [\"Epargne_menages_ratio_6MROLLING\", \"CAC40_6MROLLING\"],\n",
    "    \"Menages_DAT\": [\"Epargne_menages_ratio_6MROLLING\"],\n",
    "    \"Menages_DAV_Vol\": ['Euribor_3M_6MROLLING'], \n",
    "    \"Menages_LA_LDD\": [\"LA_rate\", 'Inflation'],\n",
    "    \"Menages_Livrets\": [\"Inflation\", \"LA_rate\"],\n",
    "    \"Menages_PEL\": [\"Epargne_menages_ratio_6MROLLING\", \"LA_rate_6MROLLING\"]\n",
    "}\n",
    "reference = 'Euribor_3M'\n",
    "\n",
    "models = {\n",
    "    \"Menages_AV_Euro_Corrige\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"Menages_AV_UC\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"Menages_DAT\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"Menages_DAV_Vol\": DecisionTreeRegressor(max_depth=3, min_samples_leaf=5),\n",
    "    \"Menages_LA_LDD\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"Menages_Livrets\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"Menages_PEL\": DecisionTreeRegressor(max_depth=3)\n",
    "}\n",
    "\n",
    "\n",
    "'''CALIBRAGE ET PREDICTION'''\n",
    "\n",
    "df_train = df[(df['Date']<=train_range[1]) & (df['Date']>=train_range[0])]\n",
    "\n",
    "global_shift = 0\n",
    "df_train['total'] = df_train[target_to_drivers.keys()].sum(axis=1)\n",
    "for (k,v) in target_to_drivers.items():\n",
    "    df_train[k+'_ratio'] = df_train[k]/df_train['total']\n",
    "    max_shift = 0\n",
    "    for driver in v:\n",
    "        if '_shifted_' in driver:\n",
    "            shift_val = int(driver.split('_')[-1])\n",
    "            df_train[driver] = df_train['_'.join(driver.split('_')[:-2])].shift(shift_val).fillna(0)\n",
    "            max_shift = max(max_shift, shift_val)\n",
    "            global_shift = max(global_shift, shift_val)\n",
    "        elif '_variation' in driver:\n",
    "            df_train[driver] = ((df_train['_'.join(driver.split('_')[:-1])] - df_train['_'.join(driver.split('_')[:-1])].shift(1)) / df_train['_'.join(driver.split('_')[:-1])].shift(1)).fillna(0.)\n",
    "        elif '_referenced' in driver:\n",
    "            df_train[driver] = (df_train['_'.join(driver.split('_')[:-1])] / df_train[reference]).fillna(0.)\n",
    "        elif \"_6MROLLING\" in driver:\n",
    "            df_train[driver] = df_train['_'.join(driver.split('_')[:-1])].rolling(6, min_periods=1).mean()\n",
    "    df_train_shift = df_train[df_train['Date']>=df_train['Date'].min()+ DateOffset(months=max_shift)]\n",
    "    if k==\"Menages_DAV_Vol\":\n",
    "        df_train_shift = df_train_shift[df_train_shift['Date']>=\"2015-04-01\"]\n",
    "    models[k] = models[k].fit(df_train_shift[v], df_train_shift[k+'_ratio'])\n",
    "    model = models[k]\n",
    "    df_train[k+'_ratio_predicted'] = model.predict(df_train[v])\n",
    "    df_train[k+'_ratio_predicted_adjusted'] = df_train[k+'_ratio_predicted'].apply(lambda x: max(x,0))\n",
    "\n",
    "standardization_factor = df_train[[x+'_ratio_predicted_adjusted' for x in target_to_drivers.keys()]].sum(axis=1)\n",
    "for (k,v) in target_to_drivers.items():\n",
    "    df_train[k+'_ratio_predicted_adjusted'] = df_train[k+'_ratio_predicted_adjusted'] / standardization_factor\n",
    "    df_train[k+'_predicted'] = df_train[k+'_ratio_predicted_adjusted']*df_train['total']\n",
    "\n",
    "df_plot = df_train.copy()\n",
    "df_plot = df_plot[df_plot['Date']>=df_plot['Date'].min()+ DateOffset(months=global_shift)].set_index('Date')\n",
    "for k in target_to_drivers.keys():\n",
    "    fig, ax =plt.subplots(1,1)\n",
    "    fig.set_figheight(4.5)\n",
    "    fig.set_figwidth(15.2)\n",
    "    \n",
    "    if k==\"Menages_DAV_Vol\":\n",
    "        figure = sns.lineplot(data=df_plot[df_plot.index>=\"2015-04-01\"][[k+'_ratio', k+'_ratio_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} ratio fit : train on [2015-04-01, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot[df_plot.index>=\"2015-04-01\"].index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[df_plot.index>=\"2015-04-01\"][[k, k+'_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} : train on [2015-04-01, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot[df_plot.index>=\"2015-04-01\"].index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        for driver in target_to_drivers[k]:\n",
    "            df_plot[driver+'_normalized'] = (df_plot[driver] - df_plot[driver].min()) / (df_plot[driver].max() - df_plot[driver].min())\n",
    "\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[df_plot.index>=\"2015-04-01\"][[d+'_normalized' for d in target_to_drivers[k]]], ax=ax)\n",
    "        figure.set_title(f\"{k} : Drivers in [2015-04-01, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot[df_plot.index>=\"2015-04-01\"].index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        figure = sns.lineplot(data=df_plot[[k+'_ratio', k+'_ratio_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} ratio fit : train on [{train_range[0]}, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot.index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[[k, k+'_predicted']], ax=ax)\n",
    "        figure.set_title(f\"{k} : train on [{train_range[0]}, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot.index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "        for driver in target_to_drivers[k]:\n",
    "            df_plot[driver+'_normalized'] = (df_plot[driver] - df_plot[driver].min()) / (df_plot[driver].max() - df_plot[driver].min())\n",
    "        fig, ax =plt.subplots(1,1)\n",
    "        fig.set_figheight(4.5)\n",
    "        fig.set_figwidth(15.2)\n",
    "        figure = sns.lineplot(data=df_plot[[d+'_normalized' for d in target_to_drivers[k]]], ax=ax)\n",
    "        figure.set_title(f\"{k} : Drivers in [{train_range[0]}, {train_range[1]}]\")\n",
    "        ticks = pd.Series(df_plot.index).dt.strftime('%Y-%m')\n",
    "        ticks = [x for x in ticks if x[-2:] in ['06', '12']]\n",
    "        figure.set_xticks(ticks)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig.show()\n",
    "\n",
    "    fig, ax =plt.subplots(1,1)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(16)\n",
    "\n",
    "    if k==\"Menages_DAV_Vol\":\n",
    "        tree.plot_tree(models[k], feature_names=[d[:12] for d in target_to_drivers[k]], ax=ax)\n",
    "        fig.suptitle(f\"{k} : tree representation, train on [2015-04-01, {train_range[1]}]\", fontsize=20)\n",
    "    else:  \n",
    "        tree.plot_tree(models[k], feature_names=[d[:15] for d in target_to_drivers[k]], ax=ax)\n",
    "        fig.suptitle(f\"{k} : tree representation, train on [{train_range[0]}, {train_range[1]}]\", fontsize=20)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfayolle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
